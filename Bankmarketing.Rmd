---
title: "BankMarketing"
group members: "Michael Grogan"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(rpart.plot)
library(MASS)
setwd("~/GitHub/DA6813CaseStudies")
```

## I - Executive Summary
## II - The Problem

The task is to analyze the dataset of customers provided by the banking institution, and determine what combination of personal characteristics and external factors are associated with the highest likelihood of the client subscribing to a term deposit. 

Ascertaining which factors are most correlated with subscribing to term deposits will allow the bank to save time and money by focusing on clients that are likely to subscribe, and avoiding those that are not.

## III - Review of Related Literature
## IV - Methodology

Read data and check for missing values
As is outlined in the case, "duration" serves no predictive purpose, because it can only be known after the call is made, and can't be used in the decision for which customer to call, so it is removed. Also removed is the pdays variable which lacks sufficient variance to provide meaningful predictive value.

Finally numeric data is normally scaled in order to condense the dimension space for calculating support vectors.

The data also needs to be balanced, because with the unmodified dataset, a classifier could achieve 90% accuracy by predicting a 'no' response for every observation.

Upsampling changes y variable name to Class.

First get an idea of most important variables using stepwise feature selection using AIC

The full model doesn't yield more accurate predictions than the step-selected model, so the different models are tested with the limited set of significant predictors.

Test several models (logistic regression, decision tree, random forest, linear SVC) using bootstrapped cross validation to optimize tuning variables



## V - Data

```{r readprepare}
bank<-read.csv('bank-additional.csv',sep=";",stringsAsFactors = T)
sum(is.na(bank))
#duration in column 11
bank<-bank[-11]

#replace month abbreviations with numbers
monthord<-as.character(bank$month)
mn<-c('jan','feb','mar','apr','may','jun','jul',
  'aug','sep','oct','nov','dec')
md<-c(1,2,3,4,5,6,7,8,9,10,11,12)
monthord[monthord %in% mn] <- md[match(monthord, mn)]
bank$month<-as.factor(monthord)

#replace day of week abbreviations with numbers
weekord<-as.character(bank$day_of_week)
mn<-c('mon','tue','wed','thu','fri','sat','sun')
md<-c(1,2,3,4,5,6,7)
weekord[weekord %in% mn] <- md[match(weekord, mn)]
bank$day_of_week<-as.factor(weekord)

#reverse levels so "yes" is returned as the positive class to the caret model
bank$y <- factor(bank$y, levels=rev(levels(bank$y)))

#scale and remove variables with near-zero variance(which turns out to be pdays)
params<-preProcess(bank,method=c("scale","nzv"))
scaledbank<-predict(params,bank)

head(scaledbank)


```
```{r trainsplit}
train<-sample(nrow(scaledbank),0.7*nrow(scaledbank))
banktrain<-scaledbank[train,]
banktest<-scaledbank[-train,]

banktrain<-upSample(x=banktrain[,-ncol(banktrain)],y=banktrain$y)


```


```{r steplog}
fullmodel<-glm(Class~.,banktrain,family=binomial)
stepped<-stepAIC(fullmodel, direction = "both",trace = FALSE)

idx <- order(coef(summary(stepped))[,4])  
out <- coef(summary(stepped))[idx,]     
head(out,15)



```



```{r plots}
attach(banktrain)
par(mfrow=c(3,1))

plot(month,Class,xlab="Month")
plot(job,Class,xlab="Job")
plot(poutcome,Class,xlab="Outcome")

detach()

```


```{r plots}
attach(banktrain)
par(mfrow=c(2,4))

plot(Class,contact,ylab="Contact")
plot(Class,age,ylab="Age")
plot(Class,marital,ylab="Marital Status")

plot(Class,campaign,ylab="Campaign")

plot(Class,cons.price.idx,ylab="Price Index")
plot(Class,cons.conf.idx,ylab="Consumer Confidence")
plot(Class,emp.var.rate,ylab="Employment")
detach()
```

```{r logreg}

set.seed(12345)


TC <- trainControl(method = "boot", number=50,classProbs=TRUE,summaryFunction = twoClassSummary)

bankLOG <- train(Class~previous+contact+campaign+cons.price.idx+cons.conf.idx+emp.var.rate+education+day_of_week, data=banktrain,
                 method = "glmnet",
                 metric="Spec",
                 trControl = TC)
bankLOGfull <- train(Class~., data=banktrain,
                 method = "glmnet",
                 metric="Spec",
                 trControl = TC)




predlog<-predict(bankLOG,banktest)

predlogfull<-predict(bankLOGfull,banktest)

print("Selected Model")
confusionMatrix(predlog,banktest$y)

print("Full Model")
confusionMatrix(predlogfull,banktest$y)


```

```{r dtree}

TC <- trainControl(method = "boot", number=50,classProbs=TRUE,summaryFunction = twoClassSummary)
#TC <- trainControl(method="repeatedcv", number=10, repeats=3,classProbs=TRUE)


banktree=train(Class~.,data=banktrain, metric="ROC",trControl=TC,method='rpart',control = rpart.control(cp=0.1,minsplit = 15, minbucket = 6))



predtree<-predict(banktree,banktest)

print("Decision Tree")
confusionMatrix(predtree,banktest$y)

```




```{r linearSVM}
set.seed(1)


TC <- trainControl(method="repeatedcv", number=10,repeats=3,
                   classProbs=TRUE,summaryFunction = twoClassSummary)

bankrad <- train(Class~poutcome+job+contact+campaign+month+cons.price.idx+cons.conf.idx+emp.var.rate, data=banktrain,
                 method = "svmLinear",
                 metric="ROC",
                 trControl = TC,
                 tuneGrid = expand.grid(C = seq(0.5, 3, length = 10)))
#)
bankrad

predrad<-predict(bankrad,banktest)

print("Linear SVM")
confusionMatrix(predrad,banktest$y)
```



```{r randomforest}

set.seed(12345)


TC <- trainControl(method = "boot", number=50,classProbs=TRUE,summaryFunction = twoClassSummary)


bankrf <- train(Class~poutcome+job+loan+contact+campaign+month+cons.price.idx+cons.conf.idx+emp.var.rate+education+day_of_week, data=banktrain,
                 method = "rf",
                 metric="ROC",
                 trControl = TC)
bankrf

predrf<-predict(bankrf,banktest)

print("Random Forest")
confusionMatrix(predrf,banktest$y)
```



## VI - Findings

Logistic regression identifies a slightly higher percentage of "yes" (subscribing to term deposits) clients, but has a lower overall accuracy than the linear SVM. This is because the rate of false "yes" predictions is twice as high for the logistic regression model. The random forest is less accurate than the SVM and has fewer true positives than the logistic regression or SVM. The model with the highest accuracy of "yes" predictions is actually the decision tree, with a positive prediction rate of 43%


## VII - Conclusions

The decision tree model "leaves money on the table" in that it doesn't predict as many of the customers who will make a term deposit as some of the other models. But the bank is not a doctor trying to catch every possible instance of cancer, instead it is trying to maximize profit. 

The cost to the bank to make one call divided by the average revenue generated by a successful call is the cost-to-revenue ratio. To recoup the cost of making calls, this ratio cannot exceed the success rate of the calls made. From this standpoint, using the decision tree model to choose which customers to call will maximize the profit as long as the cost-to-revenue ratio stays below 0.4

*** I don't know what happened or why it was different, but when I ran the program again last night, the decision tree predictive value went way down so this section doesn't reflect the results anymore. I'm trying to figure out what happened.

The only reason to use either the logistic regression or SVM classifiers would be if there were a motivation to gain as many term deposits as possible, regardless of the cost unsuccessful calls. For example, if there were a minimum number of term deposits necessary to meet some regulatory requirement, the bank would need to prioritize reaching that minimum number at the expense of profitability on those calls.

```{r}
lf<-confusionMatrix(predlogfull,banktest$y)$byClass[3]
rf<-confusionMatrix(predrf,banktest$y)$byClass[3]
svml<-confusionMatrix(predrad,banktest$y)$byClass[3]
dt<-confusionMatrix(predtree,banktest$y)$byClass[3]
#models<-c(lf,rf,svml,dt)
#colors<-c("darkgreen", "blue","red","green")

plot(x=1,y=1,ylab="Cost-To-Revenue Ratio",xlab="Call Success Rate",xlim=c(0.035,1),ylim=c(0.035,1))
abline(0,1,lwd = 2, lty = 3)
#abline(lwd = 2,v = c(lf,rf,svml,dt), col = c("darkgreen", "blue","red","green"))
#for(i in length(models)){
#  lines(c(models[i],models[i]),c(models[i],0),lwd = 2,col=colors[i])
#}
lines(c(lf,lf),c(lf,0),lwd = 2,col="darkgreen")
lines(c(rf,rf),c(rf,0),lwd = 2,col="blue")
lines(c(svml,svml),c(svml,0),lwd = 3,col="red")
lines(c(dt,dt),c(dt,0),lwd = 2,col="green")

legend("bottomright",legend=c("Logistic Regression","Random Forest","Linear SVM","Decision Tree","Break-even Profitability"),lty=c(1,1,1,1,3),lwd = 2,col = c("darkgreen", "blue","red","green","black"))
```

The decision tree has the added benefit of being clearly understandable when choosing who to call:
Make the call if the nr.employed<69 or if the cons.conf.idx< -10
```{r}
rpart.plot(banktree$finalModel)
summary(banktree)
```

```{r}
lf
rf
svml
dt
```


